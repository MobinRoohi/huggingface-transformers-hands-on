{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The `AutoTokenizer` tokenizes the raw input automatically and is the first step in the `pipline`'s work flow.\n",
        "\n",
        "We say it does it automatically, because `AutoTokenizer` automatically determines what types of tokenizer to use for the selected model."
      ],
      "metadata": {
        "id": "7Fj1SdBTk9aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "rawtext = [\n",
        "  \"Hello, how are you?\",\n",
        "  \"My name is Mobin, nice to meet you sir.\"\n",
        "]\n",
        "encoding = tokenizer(rawtext, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zax-TEYYKQa",
        "outputId": "1a438224-f44e-488c-b43c-ed741dd91dd5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  8667,   117,  1293,  1132,  1128,   136,   102,     0,     0,\n",
              "             0,     0,     0,     0],\n",
              "        [  101,  1422,  1271,  1110, 12556,  7939,   117,  3505,  1106,  2283,\n",
              "          1128,  6442,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, truncation, truncates the input if it exceeds some pre-determined model max token number.\n",
        "\n",
        "Furthermore, padding here adds [pad] token to make all inputs the same length. Then the `attention_mask` shows which parts of the input are padding and not padding, worth the model's attention.\n",
        "\n",
        "Now let us see the tokens themselves:\n",
        "\n"
      ],
      "metadata": {
        "id": "eYMZie9-khSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.tokenize(rawtext[1])\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXuis9ZhYG5P",
        "outputId": "05c60952-814c-4a32-8e09-c7d509a1b7d5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My',\n",
              " 'name',\n",
              " 'is',\n",
              " 'Mo',\n",
              " '##bin',\n",
              " ',',\n",
              " 'nice',\n",
              " 'to',\n",
              " 'meet',\n",
              " 'you',\n",
              " 'sir',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(\"سلام = salam = hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjNfdNSTmPYe",
        "outputId": "60535d0a-2a44-40ae-ce47-4e4c11d811f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['س', '##ل', '##ا', '##م', '=', 'sa', '##lam', '=', 'hello']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1WyARQUcm642"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}