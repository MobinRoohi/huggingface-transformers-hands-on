{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Named Entity Recognition Fine-Tuning\n\n## Introduction\n\nIn this notebook/project that is a part of efforts for learning the Hugging Face Transformers library, the BERT model is fine-tuned for the named entity recognition (NER) task. This time, this is accomplished using a PyTorch training loop. The dataset used is the CoNLL-2003 dataset, which contains news stories from Reuters.\n\n## Training Prepration\n\nAll the code needed before training is provided below. ","metadata":{}},{"cell_type":"code","source":"!pip install datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:03:20.409547Z","iopub.execute_input":"2024-12-31T14:03:20.409820Z","iopub.status.idle":"2024-12-31T14:03:24.965083Z","shell.execute_reply.started":"2024-12-31T14:03:20.409799Z","shell.execute_reply":"2024-12-31T14:03:24.963736Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Dataset\nfrom datasets import load_dataset\n\nraw_dataset = load_dataset(\"conll2003\")\nraw_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:03:24.966540Z","iopub.execute_input":"2024-12-31T14:03:24.966837Z","iopub.status.idle":"2024-12-31T14:03:39.081906Z","shell.execute_reply.started":"2024-12-31T14:03:24.966814Z","shell.execute_reply":"2024-12-31T14:03:39.081232Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90ef8e12d2c44e67bb3f8e22689f8ec1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a35e3d775944fe6853b110b6db87670"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93829ef9092740f58cbaa1b797171c56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df7b64e103494694a0cb212252f522a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21fa91b7ecf04f55843e6f60ebf30672"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91be171ce4b242df981dbf122ea49683"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Tokenization\nfrom transformers import AutoTokenizer\nfrom transformers import DataCollatorForTokenClassification\n\ndef align_labels_with_tokens(labels, word_ids):\n    new_labels = []\n    current_word = None\n    for word_id in word_ids:\n        if word_id != current_word:\n            # Start of a new word!\n            current_word = word_id\n            label = -100 if word_id is None else labels[word_id]\n            new_labels.append(label)\n        elif word_id is None:\n            # Special token\n            new_labels.append(-100)\n        else:\n            # Same word as previous token\n            label = labels[word_id]\n            # If the label is B-XXX we change it to I-XXX\n            if label % 2 == 1:\n                label += 1\n            new_labels.append(label)\n\n    return new_labels\n\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"], truncation=True, is_split_into_words=True\n    )\n\n    all_labels = examples[\"ner_tags\"]\n    new_labels = []\n\n    for i, labels in enumerate(all_labels):\n      word_ids = tokenized_inputs.word_ids(i)\n      new_labels.append(align_labels_with_tokens(labels, word_ids))\n\n    tokenized_inputs[\"labels\"] = new_labels\n    return tokenized_inputs\n\n\nmodel_checkpoint = \"bert-base-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\ntokenized_dataset = raw_dataset.map(\n    tokenize_and_align_labels,\n    batched=True, \n    remove_columns=raw_dataset[\"train\"].column_names\n    )\n\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:03:41.239843Z","iopub.execute_input":"2024-12-31T14:03:41.240149Z","iopub.status.idle":"2024-12-31T14:03:56.575797Z","shell.execute_reply.started":"2024-12-31T14:03:41.240127Z","shell.execute_reply":"2024-12-31T14:03:56.574946Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32e6b30875e4421e8e2c8c1c33d012ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a87ff5efddd49ea8aa9676d433e1cf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80ee223547f34614b7c0e8a261eef0e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f49fd39a75f94223bff024b00f370af7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4e6a42f7a6743ac9315c6fb57e52d41"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4f3c4fcc5bc469a9c8ca8e060235cf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d461106ca0f4d62b8a27d14c794efe1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eb28dd281284c6ea0af517bc9ad14cc"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"!pip install evaluate\n!pip install seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:03:56.577213Z","iopub.execute_input":"2024-12-31T14:03:56.577733Z","iopub.status.idle":"2024-12-31T14:04:05.919709Z","shell.execute_reply.started":"2024-12-31T14:03:56.577708Z","shell.execute_reply":"2024-12-31T14:04:05.918519Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=c7e9d333d86fe1b9ebc2b0b8c1c329fbef6b43e5ab31597f4a489ba4e1d747cf\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Metric\nimport evaluate\nimport numpy as np\n\n\nlabel_names = raw_dataset[\"train\"].features[\"ner_tags\"].feature.names\nmetric = evaluate.load(\"seqeval\")\n\ndef compute_metrics(eval_preds):\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n\n    # Remove ignored index (special tokens) and convert to labels\n    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": all_metrics[\"overall_precision\"],\n        \"recall\": all_metrics[\"overall_recall\"],\n        \"f1\": all_metrics[\"overall_f1\"],\n        \"accuracy\": all_metrics[\"overall_accuracy\"],\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:04:05.921882Z","iopub.execute_input":"2024-12-31T14:04:05.922201Z","iopub.status.idle":"2024-12-31T14:04:09.107353Z","shell.execute_reply.started":"2024-12-31T14:04:05.922177Z","shell.execute_reply":"2024-12-31T14:04:09.106416Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b89d8a81373344c59b81f907f597accd"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Model\nfrom transformers import AutoModelForTokenClassification\n\n# Model labels definition\nid2label = {i: label for i, label in enumerate(label_names)}\nlabel2id = {v: k for k, v in id2label.items()}\n\n# Model\nmodel = AutoModelForTokenClassification.from_pretrained(\n    model_checkpoint,\n    id2label=id2label,\n    label2id=label2id,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:12:57.311831Z","iopub.execute_input":"2024-12-31T14:12:57.312283Z","iopub.status.idle":"2024-12-31T14:12:57.486056Z","shell.execute_reply.started":"2024-12-31T14:12:57.312236Z","shell.execute_reply":"2024-12-31T14:12:57.485323Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"## PyTorch Training","metadata":{}},{"cell_type":"markdown","source":"First we prepare the data in PyTorch dataloaders.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(\n    tokenized_dataset[\"train\"],\n    shuffle=True,\n    collate_fn=data_collator,\n    batch_size=8\n)\neval_dataloader = DataLoader(\n    tokenized_dataset[\"validation\"], \n    collate_fn=data_collator, \n    batch_size=8\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:12:59.407297Z","iopub.execute_input":"2024-12-31T14:12:59.407601Z","iopub.status.idle":"2024-12-31T14:12:59.412105Z","shell.execute_reply.started":"2024-12-31T14:12:59.407578Z","shell.execute_reply":"2024-12-31T14:12:59.411304Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Optimizer\nfrom torch.optim import AdamW\n\noptimizer = AdamW(model.parameters(), lr=2e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:13:00.457344Z","iopub.execute_input":"2024-12-31T14:13:00.457684Z","iopub.status.idle":"2024-12-31T14:13:00.462617Z","shell.execute_reply.started":"2024-12-31T14:13:00.457660Z","shell.execute_reply":"2024-12-31T14:13:00.461569Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"Once we have all those objects, we can send them to the `accelerator.prepare()` method:","metadata":{}},{"cell_type":"code","source":"from accelerate import Accelerator\n\naccelerator = Accelerator()\nmodel, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n    model, optimizer, train_dataloader, eval_dataloader\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:13:00.847854Z","iopub.execute_input":"2024-12-31T14:13:00.848244Z","iopub.status.idle":"2024-12-31T14:13:01.004663Z","shell.execute_reply.started":"2024-12-31T14:13:00.848170Z","shell.execute_reply":"2024-12-31T14:13:01.003684Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Learning rate scheduler\nfrom transformers import get_scheduler\n\nnum_train_epochs = 3\nnum_update_steps_per_epoch = len(train_dataloader)\nnum_training_steps = num_train_epochs * num_update_steps_per_epoch\n\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:13:01.005810Z","iopub.execute_input":"2024-12-31T14:13:01.006104Z","iopub.status.idle":"2024-12-31T14:13:01.010658Z","shell.execute_reply.started":"2024-12-31T14:13:01.006076Z","shell.execute_reply":"2024-12-31T14:13:01.009669Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# Push to huggingface hub\nfrom huggingface_hub import Repository, get_full_repo_name, notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:13:01.116991Z","iopub.execute_input":"2024-12-31T14:13:01.117373Z","iopub.status.idle":"2024-12-31T14:13:01.136227Z","shell.execute_reply.started":"2024-12-31T14:13:01.117343Z","shell.execute_reply":"2024-12-31T14:13:01.135096Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9dc77d52cd04939aecc30107d32eb9e"}},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"!rm -rf /kaggle/working/bert-finetuned-ner-accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:13:01.359882Z","iopub.execute_input":"2024-12-31T14:13:01.360181Z","iopub.status.idle":"2024-12-31T14:13:01.511219Z","shell.execute_reply.started":"2024-12-31T14:13:01.360160Z","shell.execute_reply":"2024-12-31T14:13:01.509992Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"model_name = \"bert-finetuned-ner-accelerate\"\nrepo_name = get_full_repo_name(model_name)\noutput_dir = \"bert-finetuned-ner-accelerate\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:13:01.638116Z","iopub.execute_input":"2024-12-31T14:13:01.638492Z","iopub.status.idle":"2024-12-31T14:13:02.350639Z","shell.execute_reply.started":"2024-12-31T14:13:01.638463Z","shell.execute_reply":"2024-12-31T14:13:02.349664Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Metric computation\ndef postprocess(predictions, labels):\n    predictions = predictions.detach().cpu().clone().numpy()\n    labels = labels.detach().cpu().clone().numpy()\n\n    # Remove ignored index (special tokens) and convert to labels\n    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    return true_labels, true_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:13:02.351893Z","iopub.execute_input":"2024-12-31T14:13:02.352267Z","iopub.status.idle":"2024-12-31T14:13:02.357636Z","shell.execute_reply.started":"2024-12-31T14:13:02.352234Z","shell.execute_reply":"2024-12-31T14:13:02.356718Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Training Loop\nfrom tqdm.auto import tqdm\nimport torch\n\nprogress_bar = tqdm(range(num_training_steps))\nprint(f\"Using {accelerator.num_processes} GPU(s)\")\nfor epoch in range(num_train_epochs):\n    # Training\n    model.train()\n    for batch in train_dataloader:\n        outputs = model(**batch)\n        loss = outputs.loss\n        accelerator.backward(loss)\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n\n    # Evaluation\n    model.eval()\n    for batch in eval_dataloader:\n        with torch.no_grad():\n            outputs = model(**batch)\n\n        predictions = outputs.logits.argmax(dim=-1)\n        labels = batch[\"labels\"]\n\n        # Necessary to pad predictions and labels for being gathered\n        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n\n        predictions_gathered = accelerator.gather(predictions)\n        labels_gathered = accelerator.gather(labels)\n\n        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n        metric.add_batch(predictions=true_predictions, references=true_labels)\n\n    results = metric.compute()\n    print(\n        f\"epoch {epoch}:\",\n        {\n            key: results[f\"overall_{key}\"]\n            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n        },\n    )\n\n    # Save and upload\n    accelerator.wait_for_everyone()\n    unwrapped_model = accelerator.unwrap_model(model)\n    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n    if accelerator.is_main_process:\n        tokenizer.save_pretrained(output_dir)\n        # repo.push_to_hub(\n        #     commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n        # )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T14:13:02.359252Z","iopub.execute_input":"2024-12-31T14:13:02.359469Z","iopub.status.idle":"2024-12-31T14:18:31.105380Z","shell.execute_reply.started":"2024-12-31T14:13:02.359444Z","shell.execute_reply":"2024-12-31T14:18:31.104620Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5268 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1aaeaefae8840e6a09933a6d5500242"}},"metadata":{}},{"name":"stdout","text":"Using 1 GPU(s)\nepoch 0: {'precision': 0.9335240659710535, 'recall': 0.9059284664380206, 'f1': 0.9195192706174886, 'accuracy': 0.9823394360393242}\nepoch 1: {'precision': 0.9464826657691013, 'recall': 0.92393625759816, 'f1': 0.9350735722005155, 'accuracy': 0.9860628716077}\nepoch 2: {'precision': 0.9496802423426456, 'recall': 0.9304204451772465, 'f1': 0.9399516948446739, 'accuracy': 0.9863866486136458}\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}